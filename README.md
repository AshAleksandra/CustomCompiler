## El analizador lexico
Una fase es una tarea independiente usada en el proceso de compilacion. Tipicamente, muchas fases son combinadas en un solo paso. La fase del analizador lexico de un compilador (a menudo llamado scanner o tokenizador) traduce la entrada en un formato mas usable por el resto del compilador. El analizador léxico mira el flujo de entrada como una coleccion de lenguaje de elementos básicos llamado tokens. Es decir, un token es una unidad léxica indivisible. En C, palabras clave como **while** o **for** son tokens, simbolos como >, >=, >>, y >>= son tokens, nombres y numeros son tokens, etc... La cadena (string) original que comprende el token es llamado lexema. Note que no hay una relacion uno-a-uno entre lexemas y tokens. Un token de nombre o numero, por ejemplo, puede tener muchos lexemas asociados a el; un token **while** siempre coincide con el mismo lexema. La situacion es complidad con tokens que se superposicionan, (como >, >=, >>, y >>=). En general, un analizador lexico el token que coincide con lexema mas largo. Muchos lenguajes construyen este comportamiento dentro de la especificacion del lenguaje en si mismo. Dado el token >>, un token **shift** es reconocido en lugar de dos tokens **mayor-que**. 

Un analizador léxico traduce los lexemas en tokens. Los tokens normalmente se representan internamente como enteros únicos o un tipo enumerado. Siempre se requieren ambos componentes: el token en sí mismo y el lexema, que se necesita en este ejemplo para diferenciar los diversos tokens de **nombre** o **número** entre sí.

Una de las primeras decisiones de diseño que puede afectar la estructura de todo el compilador es la elección de un conjunto de tokens.